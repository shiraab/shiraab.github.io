<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<title>Creating a Trust and Safety Plan</title>
<link
      rel="stylesheet"
      href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"
      integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh"
      crossorigin="anonymous"
    />
    <link rel="stylesheet" href="./index-v2.css" type="text/css" />
</head>
<body class="body-text">
    <span id="title-menu">
      <h1>SHIRA ABRAMOVICH</h1>
      <a id="skip-nav" class="sr-only sr-only-focusable" href="#main"
        >Skip to blurb</a
      >
      <a
        id="skip-contact"
        class="sr-only sr-only-focusable"
        href="#contact-container"
        >Skip to contact</a
      >
      <div id="menu" role="navigation">
        <a href="./index.html">Home</a>
        <a class="curr-page" href="./projects.html">Projects</a>
        <a href="./about.html">About this site</a>
        <a href="./contact.html">Contact</a>
      </div>
    </span>
    <article id="0488e6a7-35c9-4b44-a9c8-ebe7169f4c46" class="page sans">
        <header>
            <div class="project-page-title">
            
            <h1>Creating a Trust and Safety Plan</h1>
            <img
            src="./complex-css/letterpress-tray.jpg"
            alt="Letterpress tray with set type and a galley label."
            class="project-page-title-image vertical"
          />
        </div>
        </header>
        <div class="project-page-two-column">
            <div class="project-page-diagram-section"></div>
            <div class="project-page-body-section">
            <h2 id="3a7fd753-2241-4c73-99de-51097105ad55" class="">Introduction</h2>
            <p id="788e18fe-4d8d-40fe-89ed-78059bfe760c" class="">Every social product under the sun has issues with equity, trust, and safety. Itâ€™s partially in the nature of humans, and partially in the nature of softwareâ€”and as a result, itâ€™s imperative that we consider our normative assumptions about what we build, and guard against the possibility of bad actors with every new feature that we make.</p>
            <p id="9a1fd935-86ea-45ac-8343-c650459e1246" class="">Iâ€™d been itching to work on issues of trust and safety since I joined Studio. This year, I had the opportunity to research and pitch a trust and safety planâ€”one that would hopefully allow us to build capacity for future social features and content moderation, and which would be feasible with a small team.</p>
            <h2 id="e5be042d-1993-4cdd-a807-0b4d323a1830" class="">Baselines: Where we began</h2>
            <p id="0e16c624-55a3-459a-a749-3f24b3a3d0eb" class="">We already had a few social features in existence before the writeup of the plan. One such feature was the Peer Group, where students in classes can interact with each other and give each other feedback. Another was Chat, where students who are in classes together can interact directly, in groups or 1:1. There was reporting functionality on all messages, but no mechanism to cut off contact with another user on the platform. Luckily, weâ€™d so far had few reported incidents.</p>
            <h2 id="a17d902b-afd5-427d-9fd7-ac130766f4e1" class="">Research</h2>
            <p id="c5ebfb14-5d45-4075-9cb7-172d05eb62e8" class="">I chose to focus my research in a few areas:</p>
            <ol type="1" id="ee1aee96-ea03-41c0-81f9-35156ba22ae0" class="numbered-list" start="1">
                <li>Existing case studies from our company: I analyzed known issues with our social infrastructure, and areas where weâ€™d had content flagged. For instance, there is a rather banal issue in some of our classes, where younger teens are matched through a random group generation process in peer groups with adults. Thereâ€™s never been an explicit issue with this, but it can feel odd and create the potential for harm.</li></ol>
                <ol type="1" id="5f6c7b59-61b4-41f4-967f-ecdef41e6f54" class="numbered-list" start="2">
                    <li>Looking at other companies that have a Trust and Safety program that I know and trust, or that are analogous to our situation. I chose two: Twitter (serious issues of trust and safety, and until recently a great safety team) and Kickstarter (analogous because of their creativity focus, and a company I highly respect for many reasons).</li></ol>
                <ol type="1" id="4b7e88fc-f9cb-4bf6-99c7-af0efce204a5" class="numbered-list" start="3">
                    <li>Reading books about issues of trust and safety. I looked around a bit and landed on <em>The Internet of Garbage</em> by Sarah Jeong, which a fantastic analysis, legal and otherwise, of spam, harassment, and hate on the Internet.</li></ol><p id="a58a4509-ce6e-45ff-acb1-ce0323ce32e4" class="">
</p>
            <p id="391c382f-5c45-439f-9cef-1810642f9ae7" class="">
                I found <em>The Internet of Garbage</em> to be particularly effective in clarifying my thinking around these issues. 
                Iâ€™d never put spam and harassment into the same category, but Jeong argues that both are bad content that make the Internet unusable. The difference? Spam prevention has extensive investment. 
                Harassment prevention does not. Cynically, I think this is because it most affects the vulnerableâ€”women, 
                people of color, and queer people, who have historically been underrepresented in the C-suite of tech and much more pessimistic about the social Internet.</p>
            <h2 id="036a583f-ef87-43c3-9ef8-4da6b934df6c" class="">Elements of the final plan</h2>
            <p id="425a70bd-8e02-4684-b8f4-746f7f853168" class="">After careful analysis, I put together a written plan that was over 2500 words long ðŸ˜…. I canâ€™t share the plan with you on my portfolio, but here are some key areas:</p>
            <ol type="1" id="c75165b0-3f47-4539-b787-9a62a7075d4d" class="numbered-list" start="1"><li>Shaping up key documents, like terms of service and community guidelines. This is a point that I gathered from Kickstarterâ€™s excellent terms of service and community guidelines, which have versions in plain text. Iâ€™m a big proponent of having plain English user agreements and/or plain English versions of all agreements.</li></ol><ol type="1" id="52c8f6fb-e2c0-4bae-be6f-634abeb838a9" class="numbered-list" start="2"><li>Create documentation for future content moderatorsâ€”for example, write out instructions for accessing specific chat messages or peer group posts. </li></ol><ol type="1" id="d130c3b8-fe70-49e1-a95c-44b149280f89" class="numbered-list" start="3"><li>Consider making social features opt-in, rather than opt-out: This is a point I took directly from Sarah Jeong, who noted that this subtle change can significantly change harassment patterns.</li></ol><ol type="1" id="5c870a3b-ceb9-4572-aa0f-6e21cc3d1fd0" class="numbered-list" start="4"><li>Implement blocking, which allows users to prevent a harassing user from contacting them, <em><em><em><em>before</em></em></em></em> expanding our social feature infrastructure.</li></ol><ol type="1" id="bbe7349e-33e2-403d-9f70-e8e9a023d656" class="numbered-list" start="5"><li>Make viewing permissions more robust, so that users can more carefully control who sees their content <em><em><em>and</em></em></em> future content moderators can see any flagged content.</li></ol><ol type="1" id="ebfa7b42-d700-4374-9bb6-938bf8fd493c" class="numbered-list" start="6"><li>Improve tooling around content hiding and removal, so that content moderators can actually take action.</li></ol><ol type="1" id="f95c2fc1-f9d5-45b3-aa05-4a3c69a93556" class="numbered-list" start="7"><li>Once ready, hire a content moderation team.</li></ol><h2 id="fec15cde-fc49-4bc7-b2cf-a7c218924ea9" class="">Actions taken</h2><p id="aa7e22da-1d0f-4d7d-b43e-b55e9133bf59" class="">Within a week of the plan being accepted, I got to begin work on <a href="./follow-block-infra.html">following and blocking work!</a> ðŸ¥³Â There was also a push to begin reevaluating our viewing permissions on most posts.</p><p id="6b41bfb4-017f-4c2c-8b3c-aab4afa65a8d" class="">Itâ€™s really exciting to see an organization encourage this kind of work, especially that early into its existence. If you work at a startup and have interest in protecting users, I would really encourage you to try and pursue it, drawing on the comprehensive research that already exists. I was really lucky to have a good background in the social issues of the Internet already, but itâ€™s never too late to start! With any safety initiative, weâ€™re able to keep the horizons of the Internet open to more people, making it a better digital place for everyone.</p><p id="29bc18ef-f6ba-4822-adc4-fc83703520a1" class="">
</p><p id="c750630e-4597-41ff-9848-83b8451201b3" class="">
</p></div></article>
<div id="contact-container">
    <span id="contact">
      <span>
        <h2>Contact:</h2>
        <p class="note">Resume available upon request.</p>
      </span>
      <ul>
        <li><a href="mailto:shira.abramovich@gmail.com">Email</a></li>
        <li>
          <a href="https://www.linkedin.com/in/shira-abramovich/">LinkedIn</a>
        </li>
        <li><a href="https://github.com/shiraab">GitHub</a></li>
        <li><a href="https://twitter.com/AbramovichShira">Twitter</a></li>
      </ul>
    </span>
  </div>
</div>
</body></html>